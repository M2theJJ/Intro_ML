# Libraries used:
 - numpy
 - sklearn


# Work done:
The data structure was created using functions provided by numpy. We split of the first column of the
csv file as the y-vector and the rest of the table as the x-matrix (excluding the header).

Next, created a reusable function that had as its input the given hyper parameters (lambda) and as its output the RSME.
That function was constructed using only functions provided by the sklearn library.
 - First we defined what linear regression model we want to use (Ridge regression in out case)
 - Then we calculate the scores via cross validation, where we split the data in 10 folds using yet another provided function.
 - In the end the scores get bundled up together and the RSME is calculated.

Lastly, the results are written into a csv file that matches the imposed data structure.


# Problems encountered:
The first problem was how to get the data structure right. We opted not to use csv or pandas but only what is available
in numpy itself, thus reducing the overall imports. From what I learned pandas is used when the csv file gets really
large, but I think the size of our csv file is not considered that large, and as such, we opted for not bloating things
too much with unnecessary imports.

Then there we really had to dig into the sklearn library to get a grasp on what functions it does provide and how they
can be used. We stumbled over a few parameters that we were unsure of and when possible we left them to their standard
value.

In the end we got some numbers but we had no intuition whatsoever if the numbers we got were even in the right ballpark.

